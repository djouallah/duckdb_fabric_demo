{"cells":[{"cell_type":"markdown","source":["**_<mark> you can use more cores to make backfill faster : 2,4,8,16,32,64</mark>_**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"180e3d93-20c5-4c24-aedd-b7fdca6cb12d"},{"cell_type":"code","source":["#%%configure\n","#{\"vCores\": 2}"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.6748352Z","session_start_time":"2025-10-02T09:43:09.6756746Z","execution_start_time":"2025-10-02T09:43:13.1045436Z","execution_finish_time":"2025-10-02T09:43:13.5265739Z","parent_msg_id":"8a228adb-8917-4c40-972f-830b87e5f75b"}},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"86b4d7de-0c1c-4a25-a1ea-6d3e2fb980b7"},{"cell_type":"code","source":["!pip install    obstore       --upgrade"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.698127Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:13.527603Z","execution_finish_time":"2025-10-02T09:43:17.9372191Z","parent_msg_id":"df7360be-7c9c-4db6-8d5e-1e5d09d85f80"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting obstore\n  Downloading obstore-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (840 bytes)\nRequirement already satisfied: typing-extensions in /home/trusted-service-user/jupyter-env/python3.11/lib/python3.11/site-packages (from obstore) (4.14.0)\nDownloading obstore-0.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: obstore\nSuccessfully installed obstore-0.8.2\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"609bd2a6-aabc-477d-ab56-0ddbc987825c"},{"cell_type":"code","source":["try:\n","    import duckdb\n","    from notebookutils.common import configs\n","    configs.tokenCacheEnabled = False\n","    duckdb.sql(\" force install delta from core_nightly;\")\n","    duckdb.sql(\"update extensions\").show()\n","except:\n","    print(\"all good\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.6994994Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:17.9386008Z","execution_finish_time":"2025-10-02T09:43:19.3517803Z","parent_msg_id":"ce3cc42b-b016-45fc-80dc-8d4e590bb99b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["┌────────────────┬──────────────┬─────────────────────┬──────────────────┬─────────────────┐\n│ extension_name │  repository  │    update_result    │ previous_version │ current_version │\n│    varchar     │   varchar    │       varchar       │     varchar      │     varchar     │\n├────────────────┼──────────────┼─────────────────────┼──────────────────┼─────────────────┤\n│ delta          │ core_nightly │ NO_UPDATE_AVAILABLE │ b60cf00          │ b60cf00         │\n│ azure          │ core         │ NO_UPDATE_AVAILABLE │ 1593cb5          │ 1593cb5         │\n└────────────────┴──────────────┴─────────────────────┴──────────────────┴─────────────────┘\n\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"ba55aad0-df98-4c9f-8813-736411704744"},{"cell_type":"code","source":["from   psutil import *\n","core              = cpu_count()\n","Nbr_threads       = (core*2)+1"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.7007656Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:19.3529416Z","execution_finish_time":"2025-10-02T09:43:19.7160528Z","parent_msg_id":"ce8fe7ba-7310-44a4-a182-56c4ff4b0a99"}},"metadata":{}}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"6ca729fe-a2c7-4c6e-8ea1-92212883b5d7"},{"cell_type":"code","source":["# please don't use a workspace name, Lakehouse and semantic_model with an empty space, or the same name of the lakehouse recently deleted\n","nbr_days_download     =  core * 160\n","lh                    = 'power' \n","schema                = 'aemo'\n","semantic_model        = \"directlake_on_onelake\" \n","ws                    =  notebookutils.runtime.context.get(\"currentWorkspaceName\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.702281Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:19.7171159Z","execution_finish_time":"2025-10-02T09:43:23.9693039Z","parent_msg_id":"11b732b4-d0b4-45b2-a306-a01492ef354b"}},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"tags":["parameters"]},"id":"94d56bdf-6445-471e-8703-946039ae4bf7"},{"cell_type":"code","source":["compaction_threshold  =  150\n","sql_folder            = 'https://github.com/djouallah/fabric_demo/raw/refs/heads/main/transformation/'\n","directlake_model      = \"https://raw.githubusercontent.com/djouallah/fabric_demo/refs/heads/main/semantic_model/directlake.bim\"\n","remaining_files       = max(0,nbr_days_download - 60)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.7034838Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:23.9704339Z","execution_finish_time":"2025-10-02T09:43:24.3670265Z","parent_msg_id":"6e309961-de1a-4a94-830a-7f0a31cbb0bf"}},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"tags":[]},"id":"06d4db22-5b31-439b-b326-642378ccc6e6"},{"cell_type":"markdown","source":["<mark>**Core Logic**</mark>"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"213d6177-c428-4d7b-b649-c3df1839d49a"},{"cell_type":"code","source":["import duckdb\n","import requests\n","import os\n","import sys\n","import importlib.util\n","from   deltalake import DeltaTable, write_deltalake\n","from   typing import List, Tuple, Union, Any, Optional, Callable, Dict\n","from   string import Template\n","class Tasksql:\n","    \"\"\"\n","    Simplified Lakehouse task runner supporting:\n","      - ('script_name', (args,))          → runs script_name.py → script_name(*args)\n","      - ('table_name', 'mode', {params})  → runs table_name.sql with params, writes to Delta\n","    \"\"\"\n","\n","    def __init__(self, workspace: str, lakehouse_name: str, schema: str, sql_folder: str, compaction_threshold: int = 10):\n","        self.workspace = workspace\n","        self.lakehouse_name = lakehouse_name\n","        self.schema = schema\n","        self.sql_folder = sql_folder.strip()\n","        self.compaction_threshold = compaction_threshold\n","        self.table_base_url = f'abfss://{self.workspace}@onelake.dfs.fabric.microsoft.com/{self.lakehouse_name}.Lakehouse/Tables/'\n","        self.con = duckdb.connect()\n","        self.con.sql(\"SET preserve_insertion_order = false\")\n","        self._attach_lakehouse()\n","\n","    @classmethod\n","    def connect(cls, workspace: str, lakehouse_name: str, schema: str, sql_folder: str, compaction_threshold: int = 10):\n","        print(\"Connecting to Lakehouse...\")\n","        return cls(workspace, lakehouse_name, schema, sql_folder.strip(), compaction_threshold)\n","\n","    def _get_storage_token(self):\n","        return os.environ.get(\"AZURE_STORAGE_TOKEN\", \"PLACEHOLDER_TOKEN_TOKEN_NOT_AVAILABLE\")\n","\n","    def _create_onelake_secret(self):\n","        token = self._get_storage_token()\n","        if token != \"PLACEHOLDER_TOKEN_TOKEN_NOT_AVAILABLE\":\n","            self.con.sql(f\"CREATE OR REPLACE SECRET onelake (TYPE AZURE, PROVIDER ACCESS_TOKEN, ACCESS_TOKEN '{token}')\")\n","        else:\n","            print(\"Please login to Azure CLI\")\n","            from azure.identity import AzureCliCredential, InteractiveBrowserCredential, ChainedTokenCredential\n","            credential = ChainedTokenCredential( AzureCliCredential(), InteractiveBrowserCredential())\n","            token = credential.get_token(\"https://storage.azure.com/.default\")\n","            os.environ[\"AZURE_STORAGE_TOKEN\"] = token.token\n","            self.con.sql(\"CREATE OR REPLACE PERSISTENT SECRET onelake (TYPE azure, PROVIDER credential_chain, CHAIN 'cli', ACCOUNT_NAME 'onelake')\")\n","\n","    def _attach_lakehouse(self):\n","        self._create_onelake_secret()\n","        try:\n","            list_tables_query = f\"\"\"\n","                SELECT DISTINCT(split_part(file, '_delta_log', 1)) as tables\n","                FROM glob (\"abfss://{self.workspace}@onelake.dfs.fabric.microsoft.com/{self.lakehouse_name}.Lakehouse/Tables/*/*/_delta_log/*.json\")\n","            \"\"\"\n","            list_tables_df = self.con.sql(list_tables_query).df()\n","            list_tables = list_tables_df['tables'].tolist() if not list_tables_df.empty else []\n","\n","            if not list_tables:\n","                print(f\"No Delta tables found in {self.lakehouse_name}.Lakehouse/Tables.\")\n","                return\n","\n","            print(f\"Found {len(list_tables)} Delta tables. Attaching as views...\")\n","\n","            for table_path in list_tables:\n","                parts = table_path.strip(\"/\").split(\"/\")\n","                if len(parts) >= 2:\n","                    potential_schema = parts[-2]\n","                    table = parts[-1]\n","                    if potential_schema == self.schema:\n","                        try:\n","                            self.con.sql(f\"\"\"\n","                                CREATE OR REPLACE VIEW {table}\n","                                AS SELECT * FROM delta_scan('{self.table_base_url}{self.schema}/{table}');\n","                            \"\"\")\n","                        except Exception as e:\n","                            print(f\"Error creating view for table {table}: {e}\")\n","            print(\"\\nAttached tables (views) in DuckDB:\")\n","            self.con.sql(\"SELECT name FROM (SHOW ALL TABLES) WHERE database='memory'\").show()\n","        except Exception as e:\n","            print(f\"Error attaching lakehouse: {e}\")\n","\n","    def _normalize_table_name(self, name: str) -> str:\n","        \"\"\"\n","        Extract base table name by taking the part before the first double underscore '__'.\n","        If no underscore, return the name as-is.\n","        \n","        Examples:\n","            'sales__update' → 'sales'\n","            'fact__daily_v2' → 'fact'\n","            'events' → 'events'\n","        \"\"\"\n","        if '__' in name:\n","            return name.split('__', 1)[0]\n","        return name\n","\n","    def _read_sql_file(self, table_name: str, params: Optional[Dict] = None) -> Optional[str]:\n","        is_url = self.sql_folder.startswith(\"http\")\n","        if is_url:\n","            url = f\"{self.sql_folder.rstrip('/')}/{table_name}.sql\".strip()\n","            try:\n","                resp = requests.get(url)\n","                resp.raise_for_status()\n","                content = resp.text\n","            except Exception as e:\n","                print(f\"Failed to fetch SQL from {url}: {e}\")\n","                return None\n","        else:\n","            path = os.path.join(self.sql_folder, f\"{table_name}.sql\")\n","            try:\n","                with open(path, 'r') as f:\n","                    content = f.read()\n","            except Exception as e:\n","                print(f\"Failed to read SQL file {path}: {e}\")\n","                return None\n","\n","        if not content.strip():\n","            print(f\"SQL file is empty: {table_name}.sql\")\n","            return None\n","\n","        # Merge system + user params\n","        full_params = {\n","            'ws': self.workspace,\n","            'lh': self.lakehouse_name,\n","            'schema': self.schema\n","        }\n","        if params:\n","            full_params.update(params)\n","\n","        # Use string.Template ($ws, ${run_date}) — safe with DuckDB {}\n","        try:\n","            template = Template(content)\n","            content = template.substitute(full_params)\n","        except KeyError as e:\n","            print(f\"Missing parameter in SQL file: ${e}\")\n","            return None\n","        except Exception as e:\n","            print(f\"Error during SQL template substitution: {e}\")\n","            return None\n","\n","        return content\n","\n","    def _load_py_function(self, name: str) -> Optional[Callable]:\n","        is_url = self.sql_folder.startswith(\"http\")\n","        try:\n","            if is_url:\n","                url = f\"{self.sql_folder.rstrip('/')}/{name}.py\".strip()\n","                resp = requests.get(url)\n","                resp.raise_for_status()\n","                code = resp.text\n","                namespace = {}\n","                exec(code, namespace)\n","                func = namespace.get(name)\n","                return func if callable(func) else None\n","            else:\n","                path = os.path.join(self.sql_folder, f\"{name}.py\")\n","                if not os.path.isfile(path):\n","                    print(f\"Python file not found: {path}\")\n","                    return None\n","                spec = importlib.util.spec_from_file_location(name, path)\n","                mod = importlib.util.module_from_spec(spec)\n","                spec.loader.exec_module(mod)\n","                func = getattr(mod, name, None)\n","                return func if callable(func) else None\n","        except Exception as e:\n","            print(f\"Error loading Python function '{name}': {e}\")\n","            return None\n","\n","    def _run_py_task(self, name: str, args: tuple) -> int:\n","        self._create_onelake_secret()\n","        func = self._load_py_function(name)\n","        if not func:\n","            return 0\n","        try:\n","            print(f\"Running Python task: {name}{args}\")\n","            result = func(*args)\n","            print(f\"✅ Python task '{name}' completed.\")\n","            return result\n","        except Exception as e:\n","            print(f\"❌ Error in Python task '{name}': {e}\")\n","            return 0\n","\n","    def _run_sql_task(self, table: str, mode: str, params: Optional[Dict] = None) -> int:\n","        self._create_onelake_secret()\n","        allowed_modes = {'overwrite', 'append', 'ignore'}\n","        if mode not in allowed_modes:\n","            print(f\"Invalid mode '{mode}'. Use: {allowed_modes}\")\n","            return 0\n","\n","        sql = self._read_sql_file(table, params)  # loads table.sql or table_anything.sql as-is\n","        if sql is None:\n","            return 0\n","\n","        normalized_table = self._normalize_table_name(table)\n","        path = f\"{self.table_base_url}{self.schema}/{normalized_table}\"\n","\n","        try:\n","            if mode == 'overwrite':\n","                self.con.sql(f\"DROP VIEW IF EXISTS {normalized_table}\")\n","                df = self.con.sql(sql).record_batch()\n","                write_deltalake(path, df, mode='overwrite')\n","                self.con.sql(f\"CREATE OR REPLACE VIEW {normalized_table} AS SELECT * FROM delta_scan('{path}')\")\n","                dt = DeltaTable(path)\n","                dt.vacuum(retention_hours=0, dry_run=False, enforce_retention_duration=False)\n","                dt.cleanup_metadata()\n","\n","            elif mode == 'append':\n","                df = self.con.sql(sql).record_batch()\n","                write_deltalake(path, df, mode='append')\n","                self.con.sql(f\"CREATE OR REPLACE VIEW {normalized_table} AS SELECT * FROM delta_scan('{path}')\")\n","                dt = DeltaTable(path)\n","                if len(dt.file_uris()) > self.compaction_threshold:\n","                    print(f\"Compacting {normalized_table} (files: {len(dt.file_uris())})\")\n","                    dt.optimize.compact()\n","                    dt.vacuum(dry_run=False)\n","                    dt.cleanup_metadata()\n","\n","            elif mode == 'ignore':\n","                try:\n","                    DeltaTable(path)\n","                    print(f\"Table {normalized_table} exists. Skipping (mode='ignore').\")\n","                except Exception:\n","                    print(f\"{normalized_table} doesn't exist. Creating in overwrite mode.\")\n","                    self.con.sql(f\"DROP VIEW IF EXISTS {normalized_table}\")\n","                    df = self.con.sql(sql).record_batch()\n","                    write_deltalake(path, df, mode='overwrite')\n","                    self.con.sql(f\"CREATE OR REPLACE VIEW {normalized_table} AS SELECT * FROM delta_scan('{path}')\")\n","                    dt = DeltaTable(path)\n","                    dt.vacuum(dry_run=False)\n","                    dt.cleanup_metadata()\n","\n","            print(f\"✅ SQL task '{table}' → table '{normalized_table}' ({mode}) completed.\")\n","            return 1\n","\n","        except Exception as e:\n","            print(f\"❌ Error in SQL task '{table}' (writing to '{normalized_table}'): {e}\")\n","            return 0\n","\n","    def run_pipeline(self, tasks: List[Union[Tuple[str, tuple], Tuple[str, str, Dict]]]) -> bool:\n","        \"\"\"\n","        Run tasks with simple syntax:\n","          - ('download', (url_list, path_list, depth))\n","          - ('staging_table', 'overwrite', {'run_date': '2024-06-01'})\n","        \"\"\"\n","        for i, task in enumerate(tasks):\n","            print(f\"\\n--- Running Task {i+1}: {task[0]} ---\")\n","            name = task[0]\n","\n","            if len(task) == 2:\n","                # Python task: ('name', (args,))\n","                args = task[1]\n","                if not isinstance(args, (tuple, list)):\n","                    args = (args,)\n","                result = self._run_py_task(name, tuple(args))\n","            elif len(task) == 3:\n","                # SQL write task: ('table', 'mode', {params})\n","                mode, params = task[1], task[2]\n","                if not isinstance(params, dict):\n","                    print(f\"❌ Expected dict as 3rd item in SQL task, got {type(params)}\")\n","                    return False\n","                result = self._run_sql_task(name, mode, params)\n","            else:\n","                print(f\"❌ Invalid task format: {task}\")\n","                return False\n","\n","            if result != 1:\n","                print(f\"❌ Task {i+1} failed. Stopping.\")\n","                return False\n","\n","        print(\"\\n✅ All tasks completed successfully.\")\n","        return True\n","\n","    def get_connection(self):\n","        return self.con\n","\n","    def close(self):\n","        if self.con:\n","            self.con.close()\n","            print(\"DuckDB connection closed.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.7049085Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:24.3682788Z","execution_finish_time":"2025-10-02T09:43:27.5170565Z","parent_msg_id":"a35f8334-dc15-4b24-8ce9-4e1d28ad10f4"}},"metadata":{}}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":true},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"02e7908e-78cb-4a78-92fa-7e40d60a7185"},{"cell_type":"code","source":["%%time\n","con = Tasksql.connect( ws,lh,schema, sql_folder, compaction_threshold  )"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.7063282Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:27.5182559Z","execution_finish_time":"2025-10-02T09:43:29.666983Z","parent_msg_id":"30c94623-42a5-46ec-9644-8d4927fc2895"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Connecting to Lakehouse...\nNo Delta tables found in power.Lakehouse/Tables.\nCPU times: user 228 ms, sys: 7.48 ms, total: 236 ms\nWall time: 1.41 s\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"f02dab12-9c27-4be1-b4f4-4fca2d598dd0"},{"cell_type":"code","source":["nightly =[\n","              \n","              ('scrapingv2', ([\"https://nemweb.com.au/Reports/Current/Daily_Reports/\"],[\"Reports/Current/Daily_Reports/\"],nbr_days_download,ws,lh,Nbr_threads)),\n","              ('price','append',{'ws': ws,'lh':lh}),\n","              ('scada','append',{'ws': ws,'lh':lh}),\n","              ('download_excel',(\"raw/\", ws,lh)),\n","              ('duid','overwrite',{'ws': ws,'lh':lh}),\n","              ('calendar','ignore',{}),\n","              ('mstdatetime','ignore',{}),\n","              ('summary__backfill','overwrite',{})\n","         ]\n","\n","intraday = [\n","              ('scrapingv2', ([\"http://nemweb.com.au/Reports/Current/DispatchIS_Reports/\",\"http://nemweb.com.au/Reports/Current/Dispatch_SCADA/\" ],\n","                            [\"Reports/Current/DispatchIS_Reports/\",\"Reports/Current/Dispatch_SCADA/\"],\n","                             288, ws,lh,Nbr_threads)),\n","              ('price_today','append',{'ws': ws,'lh':lh}),\n","              ('scada_today','append',{'ws': ws,'lh':lh}),\n","              ('duid','ignore',{'ws': ws,'lh':lh}),\n","              ('summary__incremental', 'append',{})            \n","          ]\n","\n","history_download = [('scrapingv2',([\"https://github.com/djouallah/fabric_demo/tree/main/data/archive/*\"],[\"Reports/Current/Daily_Reports/\"],remaining_files,ws,lh,Nbr_threads))]\n","\n","history_process = [('scada','append',{'ws': ws,'lh':lh}),('price','append',{'ws': ws,'lh':lh}),('summary__backfill_archive','append',{})]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.7078023Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:29.6682099Z","execution_finish_time":"2025-10-02T09:43:30.0648819Z","parent_msg_id":"eb78605c-d136-4576-bce1-da2775944b32"}},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"jupyter":{"source_hidden":true}},"id":"0cb55004-4897-450e-ae9d-42266a576085"},{"cell_type":"code","source":["%%time\n","#create lakehouse if not exists\n","con.run_pipeline([('create_lakehouse_if_not_exists', (lh))])"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"finished","queued_time":"2025-10-02T09:43:09.709124Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:30.066153Z","execution_finish_time":"2025-10-02T09:43:32.1942459Z","parent_msg_id":"e2834a44-b156-4d73-b60b-46621feb45ff"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Running Task 1: create_lakehouse_if_not_exists ---\nRunning Python task: create_lakehouse_if_not_exists('power',)\n✅ Python task 'create_lakehouse_if_not_exists' completed.\n\n✅ All tasks completed successfully.\nCPU times: user 86.1 ms, sys: 6.97 ms, total: 93 ms\nWall time: 1.37 s\n"]},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"True"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"84c588ea-e9ff-4656-ab7d-b4bf656d3fbd"},{"cell_type":"code","source":["%%time\n","#initial load\n","con.run_pipeline(nightly)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"a661efb5-dca6-455a-af70-c8c4e2b98149","normalized_state":"running","queued_time":"2025-10-02T09:43:09.7106213Z","session_start_time":null,"execution_start_time":"2025-10-02T09:43:32.1954518Z","execution_finish_time":null,"parent_msg_id":"8e85e8e5-b82f-4b65-bb5f-4f991ba74da9"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Running Task 1: scrapingv2 ---\nRunning Python task: scrapingv2(['https://nemweb.com.au/Reports/Current/Daily_Reports/'], ['Reports/Current/Daily_Reports/'], 320, 'testdirectlake', 'power', 5)\nCould not read log file Reports/Current/Daily_Reports/download_log.csv: Object at location power.Lakehouse/Files/Reports/Current/Daily_Reports/download_log.csv not found: Error performing GET https://onelake.blob.fabric.microsoft.com/testdirectlake/power.Lakehouse/Files/Reports/Current/Daily_Reports/download_log.csv in 251.547891ms - Server returned non-2xx status code: 404 Not Found: {\"error\":{\"code\":\"PathNotFound\",\"message\":\"The specified path does not exist.\\nRequestId:85d43aa1-e01f-00d2-3281-33788b000000\\nTime:2025-10-02T09:43:32.6481957Z\"}}\n\nDebug source:\nNotFound {\n    path: \"power.Lakehouse/Files/Reports/Current/Daily_Reports/download_log.csv\",\n    source: RetryError(\n        RetryErrorImpl {\n            method: GET,\n            uri: Some(\n                https://onelake.blob.fabric.microsoft.com/testdirectlake/power.Lakehouse/Files/Reports/Current/Daily_Reports/download_log.csv,\n            ),\n            retries: 0,\n            max_retries: 10,\n            elapsed: 251.547891ms,\n            retry_timeout: 180s,\n            inner: Status {\n                status: 404,\n                body: Some(\n                    \"{\\\"error\\\":{\\\"code\\\":\\\"PathNotFound\\\",\\\"message\\\":\\\"The specified path does not exist.\\\\nRequestId:85d43aa1-e01f-00d2-3281-33788b000000\\\\nTime:2025-10-02T09:43:32.6481957Z\\\"}}\",\n                ),\n            },\n        },\n    ),\n}\n"]}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3348a4c5-068e-4300-a046-dd1f1da97b28"},{"cell_type":"code","source":["%%time\n","#create  semantic model\n","con.run_pipeline([('deploy_modelv2', (lh,schema,semantic_model,directlake_model))])"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":null,"normalized_state":"waiting","queued_time":"2025-10-02T09:43:09.7118676Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"463e1ae5-ffed-4a33-8f1c-55e4ad7f1d79"}},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"9890da21-9416-48b8-b75c-fb84e9689f72"},{"cell_type":"code","source":["%%time\n","#load today data\n","con.run_pipeline(intraday)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":null,"normalized_state":"waiting","queued_time":"2025-10-02T09:43:09.7131104Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"7f7696eb-073a-46d8-a800-edfe7244ac7a"}},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3eed16b6-c7e1-4fb7-b85a-e7fb40c4ccf5"},{"cell_type":"code","source":["%%time\n","if remaining_files > 0:\n","    ## you can turn it off when Historical data is fully loaded\n","    con.run_pipeline(history_download)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":null,"normalized_state":"waiting","queued_time":"2025-10-02T09:43:09.7143906Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"320ecd3a-b281-4374-a6be-3a678511890f"}},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"a62bd1bb-42c1-46a7-8e02-7bb1b9125b98"},{"cell_type":"code","source":["if remaining_files > 0:\n","    con.run_pipeline(history_process)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":null,"normalized_state":"waiting","queued_time":"2025-10-02T09:43:09.7159067Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"f90d8b5c-c12c-4b6f-a83b-5f337034b1c5"}},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"85e955e8-e5fa-4915-afd1-ec318123e2f8"}],"metadata":{"kernel_info":{"jupyter_kernel_name":"python3.11","name":"jupyter"},"kernelspec":{"name":"jupyter","display_name":"Jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"version_major":2,"version_minor":0,"state":{"4f7e606fa01749fe95147eef006af2cb":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":100,"style":"IPY_MODEL_c69898b22dd8452fb38a7ef6f38613ae","layout":"IPY_MODEL_4e3760e8598c40f3a6f68dd3e5cc418f"}},"4e3760e8598c40f3a6f68dd3e5cc418f":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"auto"}},"c69898b22dd8452fb38a7ef6f38613ae":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","bar_color":"black"}},"8f74f115c75a43c785cf171b4b5bb1ed":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":3,"style":"IPY_MODEL_6626d9d44bc14f2d874d14fc92f46c44","layout":"IPY_MODEL_fd199eb0ee9747c9a9b5b4cbe81fbdc3"}},"fd199eb0ee9747c9a9b5b4cbe81fbdc3":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"auto"}},"6626d9d44bc14f2d874d14fc92f46c44":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","bar_color":"black"}}}}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}