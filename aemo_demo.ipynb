{"cells":[{"cell_type":"markdown","source":["**_<mark> you can use more cores to make backfill faster : 2,4,8,16,32,64</mark>_**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"180e3d93-20c5-4c24-aedd-b7fdca6cb12d"},{"cell_type":"code","source":["#%%configure\n","#{\"vCores\": 2}"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3719437Z","session_start_time":"2025-10-01T08:26:14.3728744Z","execution_start_time":"2025-10-01T08:26:18.5139921Z","execution_finish_time":"2025-10-01T08:26:18.9463886Z","parent_msg_id":"40efa6e4-0121-4145-b4a1-69a67e6bc1e0"}},"metadata":{}}],"execution_count":1,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"86b4d7de-0c1c-4a25-a1ea-6d3e2fb980b7"},{"cell_type":"code","source":["!pip install    -q obstore       --upgrade\n","!pip install    -q duckdb        --upgrade\n","!pip install    -q deltalake     --upgrade\n","!pip install    -q semantic-link-labs\n","notebookutils.session.restartPython()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3754947Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:18.9476131Z","execution_finish_time":"2025-10-01T08:26:44.2569676Z","parent_msg_id":"ec1e0114-0ab2-47e7-8e01-588a7c9c1dc2"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["sys.exit called with value 0. The interpreter will be restarted.\n"]}],"execution_count":2,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"609bd2a6-aabc-477d-ab56-0ddbc987825c"},{"cell_type":"code","source":["from   psutil import *\n","core              = cpu_count()\n","Nbr_threads       = (core*2)+1\n","print(core)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3769003Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:44.2582825Z","execution_finish_time":"2025-10-01T08:26:46.3132502Z","parent_msg_id":"54e5bef3-0b9e-47fc-9cf3-34025958cfec"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["2\n"]}],"execution_count":3,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"94ec4e22-0d37-4cde-8cf9-2169ba5e4c9a"},{"cell_type":"code","source":["try:\n","    import duckdb\n","    from notebookutils.common import configs\n","    configs.tokenCacheEnabled = False\n","    duckdb.sql(\" force install delta from core_nightly;\")\n","    duckdb.sql(\"update extensions\").show()\n","except:\n","    print(\"all good\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3784774Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:46.3153207Z","execution_finish_time":"2025-10-01T08:26:47.7975442Z","parent_msg_id":"121971f7-f1c6-4661-a60c-b9a3af53d170"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["┌────────────────┬──────────────┬─────────────────────┬──────────────────┬─────────────────┐\n│ extension_name │  repository  │    update_result    │ previous_version │ current_version │\n│    varchar     │   varchar    │       varchar       │     varchar      │     varchar     │\n├────────────────┼──────────────┼─────────────────────┼──────────────────┼─────────────────┤\n│ delta          │ core_nightly │ NO_UPDATE_AVAILABLE │ 03aaf0f          │ 03aaf0f         │\n│ azure          │ core         │ NO_UPDATE_AVAILABLE │ 5e458fc          │ 5e458fc         │\n└────────────────┴──────────────┴─────────────────────┴──────────────────┴─────────────────┘\n\n"]}],"execution_count":4,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"ba55aad0-df98-4c9f-8813-736411704744"},{"cell_type":"code","source":["# please don't use a workspace name, Lakehouse and semantic_model with an empty space, or the same name of the lakehouse recently deleted\n","lh                    = 'dfcvb' \n","schema                = 'xcv'\n","semantic_model        = \"ssdf\"  # Name for the deployed semantic model"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3799248Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:47.7987746Z","execution_finish_time":"2025-10-01T08:26:48.2346144Z","parent_msg_id":"0643a1b5-7d98-4b3b-825b-7d8c1648b0cc"}},"metadata":{}}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"tags":["parameters"]},"id":"94d56bdf-6445-471e-8703-946039ae4bf7"},{"cell_type":"code","source":["ws                    =  notebookutils.runtime.context.get(\"currentWorkspaceName\")\n","compaction_threshold  =  150\n","sql_folder            = 'https://github.com/djouallah/fabric_demo/raw/refs/heads/main/transformation/'\n","nbr_days_download     = int(core * 360)  # or change accordingly, in all cases the data is loaded incrementally "],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3812588Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:48.2358243Z","execution_finish_time":"2025-10-01T08:26:49.6966714Z","parent_msg_id":"3d7eadc8-a433-43e6-b057-4fa1aa6d09d1"}},"metadata":{}}],"execution_count":6,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"tags":[]},"id":"06d4db22-5b31-439b-b326-642378ccc6e6"},{"cell_type":"markdown","source":["<mark>**Core Logic**</mark>"],"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"},"nteract":{"transient":{"deleting":false}}},"id":"213d6177-c428-4d7b-b649-c3df1839d49a"},{"cell_type":"code","source":["import duckdb\n","import requests\n","import os\n","import sys\n","import importlib.util\n","from   deltalake import DeltaTable, write_deltalake\n","from   typing import List, Tuple, Union, Any, Optional, Callable, Dict\n","from   string import Template\n","class Tasksql:\n","    \"\"\"\n","    Simplified Lakehouse task runner supporting:\n","      - ('script_name', (args,))          → runs script_name.py → script_name(*args)\n","      - ('table_name', 'mode', {params})  → runs table_name.sql with params, writes to Delta\n","    \"\"\"\n","\n","    def __init__(self, workspace: str, lakehouse_name: str, schema: str, sql_folder: str, compaction_threshold: int = 10):\n","        self.workspace = workspace\n","        self.lakehouse_name = lakehouse_name\n","        self.schema = schema\n","        self.sql_folder = sql_folder.strip()\n","        self.compaction_threshold = compaction_threshold\n","        self.table_base_url = f'abfss://{self.workspace}@onelake.dfs.fabric.microsoft.com/{self.lakehouse_name}.Lakehouse/Tables/'\n","        self.con = duckdb.connect()\n","        self.con.sql(\"SET preserve_insertion_order = false\")\n","        self._attach_lakehouse()\n","\n","    @classmethod\n","    def connect(cls, workspace: str, lakehouse_name: str, schema: str, sql_folder: str, compaction_threshold: int = 10):\n","        print(\"Connecting to Lakehouse...\")\n","        return cls(workspace, lakehouse_name, schema, sql_folder.strip(), compaction_threshold)\n","\n","    def _get_storage_token(self):\n","        return os.environ.get(\"AZURE_STORAGE_TOKEN\", \"PLACEHOLDER_TOKEN_TOKEN_NOT_AVAILABLE\")\n","\n","    def _create_onelake_secret(self):\n","        token = self._get_storage_token()\n","        if token != \"PLACEHOLDER_TOKEN_TOKEN_NOT_AVAILABLE\":\n","            self.con.sql(f\"CREATE OR REPLACE SECRET onelake (TYPE AZURE, PROVIDER ACCESS_TOKEN, ACCESS_TOKEN '{token}')\")\n","        else:\n","            print(\"Please login to Azure CLI\")\n","            from azure.identity import AzureCliCredential, InteractiveBrowserCredential, ChainedTokenCredential\n","            credential = ChainedTokenCredential( AzureCliCredential(), InteractiveBrowserCredential())\n","            token = credential.get_token(\"https://storage.azure.com/.default\")\n","            os.environ[\"AZURE_STORAGE_TOKEN\"] = token.token\n","            self.con.sql(\"CREATE OR REPLACE PERSISTENT SECRET onelake (TYPE azure, PROVIDER credential_chain, CHAIN 'cli', ACCOUNT_NAME 'onelake')\")\n","\n","    def _attach_lakehouse(self):\n","        self._create_onelake_secret()\n","        try:\n","            list_tables_query = f\"\"\"\n","                SELECT DISTINCT(split_part(file, '_delta_log', 1)) as tables\n","                FROM glob (\"abfss://{self.workspace}@onelake.dfs.fabric.microsoft.com/{self.lakehouse_name}.Lakehouse/Tables/*/*/_delta_log/*.json\")\n","            \"\"\"\n","            list_tables_df = self.con.sql(list_tables_query).df()\n","            list_tables = list_tables_df['tables'].tolist() if not list_tables_df.empty else []\n","\n","            if not list_tables:\n","                print(f\"No Delta tables found in {self.lakehouse_name}.Lakehouse/Tables.\")\n","                return\n","\n","            print(f\"Found {len(list_tables)} Delta tables. Attaching as views...\")\n","\n","            for table_path in list_tables:\n","                parts = table_path.strip(\"/\").split(\"/\")\n","                if len(parts) >= 2:\n","                    potential_schema = parts[-2]\n","                    table = parts[-1]\n","                    if potential_schema == self.schema:\n","                        try:\n","                            self.con.sql(f\"\"\"\n","                                CREATE OR REPLACE VIEW {table}\n","                                AS SELECT * FROM delta_scan('{self.table_base_url}{self.schema}/{table}');\n","                            \"\"\")\n","                        except Exception as e:\n","                            print(f\"Error creating view for table {table}: {e}\")\n","            print(\"\\nAttached tables (views) in DuckDB:\")\n","            self.con.sql(\"SELECT name FROM (SHOW ALL TABLES) WHERE database='memory'\").show()\n","        except Exception as e:\n","            print(f\"Error attaching lakehouse: {e}\")\n","\n","    def _normalize_table_name(self, name: str) -> str:\n","        \"\"\"\n","        Extract base table name by taking the part before the first double underscore '__'.\n","        If no underscore, return the name as-is.\n","        \n","        Examples:\n","            'sales__update' → 'sales'\n","            'fact__daily_v2' → 'fact'\n","            'events' → 'events'\n","        \"\"\"\n","        if '__' in name:\n","            return name.split('__', 1)[0]\n","        return name\n","\n","    def _read_sql_file(self, table_name: str, params: Optional[Dict] = None) -> Optional[str]:\n","        is_url = self.sql_folder.startswith(\"http\")\n","        if is_url:\n","            url = f\"{self.sql_folder.rstrip('/')}/{table_name}.sql\".strip()\n","            try:\n","                resp = requests.get(url)\n","                resp.raise_for_status()\n","                content = resp.text\n","            except Exception as e:\n","                print(f\"Failed to fetch SQL from {url}: {e}\")\n","                return None\n","        else:\n","            path = os.path.join(self.sql_folder, f\"{table_name}.sql\")\n","            try:\n","                with open(path, 'r') as f:\n","                    content = f.read()\n","            except Exception as e:\n","                print(f\"Failed to read SQL file {path}: {e}\")\n","                return None\n","\n","        if not content.strip():\n","            print(f\"SQL file is empty: {table_name}.sql\")\n","            return None\n","\n","        # Merge system + user params\n","        full_params = {\n","            'ws': self.workspace,\n","            'lh': self.lakehouse_name,\n","            'schema': self.schema\n","        }\n","        if params:\n","            full_params.update(params)\n","\n","        # Use string.Template ($ws, ${run_date}) — safe with DuckDB {}\n","        try:\n","            template = Template(content)\n","            content = template.substitute(full_params)\n","        except KeyError as e:\n","            print(f\"Missing parameter in SQL file: ${e}\")\n","            return None\n","        except Exception as e:\n","            print(f\"Error during SQL template substitution: {e}\")\n","            return None\n","\n","        return content\n","\n","    def _load_py_function(self, name: str) -> Optional[Callable]:\n","        is_url = self.sql_folder.startswith(\"http\")\n","        try:\n","            if is_url:\n","                url = f\"{self.sql_folder.rstrip('/')}/{name}.py\".strip()\n","                resp = requests.get(url)\n","                resp.raise_for_status()\n","                code = resp.text\n","                namespace = {}\n","                exec(code, namespace)\n","                func = namespace.get(name)\n","                return func if callable(func) else None\n","            else:\n","                path = os.path.join(self.sql_folder, f\"{name}.py\")\n","                if not os.path.isfile(path):\n","                    print(f\"Python file not found: {path}\")\n","                    return None\n","                spec = importlib.util.spec_from_file_location(name, path)\n","                mod = importlib.util.module_from_spec(spec)\n","                spec.loader.exec_module(mod)\n","                func = getattr(mod, name, None)\n","                return func if callable(func) else None\n","        except Exception as e:\n","            print(f\"Error loading Python function '{name}': {e}\")\n","            return None\n","\n","    def _run_py_task(self, name: str, args: tuple) -> int:\n","        self._create_onelake_secret()\n","        func = self._load_py_function(name)\n","        if not func:\n","            return 0\n","        try:\n","            print(f\"Running Python task: {name}{args}\")\n","            result = func(*args)\n","            print(f\"✅ Python task '{name}' completed.\")\n","            return result\n","        except Exception as e:\n","            print(f\"❌ Error in Python task '{name}': {e}\")\n","            return 0\n","\n","    def _run_sql_task(self, table: str, mode: str, params: Optional[Dict] = None) -> int:\n","        self._create_onelake_secret()\n","        allowed_modes = {'overwrite', 'append', 'ignore'}\n","        if mode not in allowed_modes:\n","            print(f\"Invalid mode '{mode}'. Use: {allowed_modes}\")\n","            return 0\n","\n","        sql = self._read_sql_file(table, params)  # loads table.sql or table_anything.sql as-is\n","        if sql is None:\n","            return 0\n","\n","        normalized_table = self._normalize_table_name(table)\n","        path = f\"{self.table_base_url}{self.schema}/{normalized_table}\"\n","\n","        try:\n","            if mode == 'overwrite':\n","                self.con.sql(f\"DROP VIEW IF EXISTS {normalized_table}\")\n","                df = self.con.sql(sql).arrow()\n","                write_deltalake(path, df, mode='overwrite')\n","                self.con.sql(f\"CREATE OR REPLACE VIEW {normalized_table} AS SELECT * FROM delta_scan('{path}')\")\n","                dt = DeltaTable(path)\n","                dt.vacuum(retention_hours=0, dry_run=False, enforce_retention_duration=False)\n","                dt.cleanup_metadata()\n","\n","            elif mode == 'append':\n","                df = self.con.sql(sql).arrow()\n","                write_deltalake(path, df, mode='append')\n","                self.con.sql(f\"CREATE OR REPLACE VIEW {normalized_table} AS SELECT * FROM delta_scan('{path}')\")\n","                dt = DeltaTable(path)\n","                if len(dt.file_uris()) > self.compaction_threshold:\n","                    print(f\"Compacting {normalized_table} (files: {len(dt.file_uris())})\")\n","                    dt.optimize.compact()\n","                    dt.vacuum(dry_run=False)\n","                    dt.cleanup_metadata()\n","\n","            elif mode == 'ignore':\n","                try:\n","                    DeltaTable(path)\n","                    print(f\"Table {normalized_table} exists. Skipping (mode='ignore').\")\n","                except Exception:\n","                    print(f\"{normalized_table} doesn't exist. Creating in overwrite mode.\")\n","                    self.con.sql(f\"DROP VIEW IF EXISTS {normalized_table}\")\n","                    df = self.con.sql(sql).arrow()\n","                    write_deltalake(path, df, mode='overwrite')\n","                    self.con.sql(f\"CREATE OR REPLACE VIEW {normalized_table} AS SELECT * FROM delta_scan('{path}')\")\n","                    dt = DeltaTable(path)\n","                    dt.vacuum(dry_run=False)\n","                    dt.cleanup_metadata()\n","\n","            print(f\"✅ SQL task '{table}' → table '{normalized_table}' ({mode}) completed.\")\n","            return 1\n","\n","        except Exception as e:\n","            print(f\"❌ Error in SQL task '{table}' (writing to '{normalized_table}'): {e}\")\n","            return 0\n","\n","    def run_pipeline(self, tasks: List[Union[Tuple[str, tuple], Tuple[str, str, Dict]]]) -> bool:\n","        \"\"\"\n","        Run tasks with simple syntax:\n","          - ('download', (url_list, path_list, depth))\n","          - ('staging_table', 'overwrite', {'run_date': '2024-06-01'})\n","        \"\"\"\n","        for i, task in enumerate(tasks):\n","            print(f\"\\n--- Running Task {i+1}: {task[0]} ---\")\n","            name = task[0]\n","\n","            if len(task) == 2:\n","                # Python task: ('name', (args,))\n","                args = task[1]\n","                if not isinstance(args, (tuple, list)):\n","                    args = (args,)\n","                result = self._run_py_task(name, tuple(args))\n","            elif len(task) == 3:\n","                # SQL write task: ('table', 'mode', {params})\n","                mode, params = task[1], task[2]\n","                if not isinstance(params, dict):\n","                    print(f\"❌ Expected dict as 3rd item in SQL task, got {type(params)}\")\n","                    return False\n","                result = self._run_sql_task(name, mode, params)\n","            else:\n","                print(f\"❌ Invalid task format: {task}\")\n","                return False\n","\n","            if result != 1:\n","                print(f\"❌ Task {i+1} failed. Stopping.\")\n","                return False\n","\n","        print(\"\\n✅ All tasks completed successfully.\")\n","        return True\n","\n","    def get_connection(self):\n","        return self.con\n","\n","    def close(self):\n","        if self.con:\n","            self.con.close()\n","            print(\"DuckDB connection closed.\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3922751Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:49.6980762Z","execution_finish_time":"2025-10-01T08:26:50.1392198Z","parent_msg_id":"114e7163-30da-4bda-9424-c657906b6bb9"}},"metadata":{}}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":true},"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"02e7908e-78cb-4a78-92fa-7e40d60a7185"},{"cell_type":"code","source":["%%time\n","con = Tasksql.connect( ws,lh,schema, sql_folder, compaction_threshold  )"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.3935583Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:50.1404538Z","execution_finish_time":"2025-10-01T08:26:57.5509079Z","parent_msg_id":"d22e3f45-7c62-45d8-a0f2-039a234b2a8d"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Connecting to Lakehouse...\nFound 8 Delta tables. Attaching as views...\n\nAttached tables (views) in DuckDB:\n┌─────────────┐\n│    name     │\n│   varchar   │\n├─────────────┤\n│ calendar    │\n│ duid        │\n│ mstdatetime │\n│ price       │\n│ price_today │\n│ scada       │\n│ scada_today │\n│ summary     │\n└─────────────┘\n\nCPU times: user 2.82 s, sys: 219 ms, total: 3.04 s\nWall time: 5.85 s\n"]}],"execution_count":8,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"f02dab12-9c27-4be1-b4f4-4fca2d598dd0"},{"cell_type":"code","source":["nightly =[\n","              ('create_lakehouse_if_not_exists', (lh)),\n","              ('scrapingv2', ([\"https://nemweb.com.au/Reports/Current/Daily_Reports/\"],[\"Reports/Current/Daily_Reports/\"],7,ws,lh,Nbr_threads)),\n","              ('price','append',{'ws': ws,'lh':lh}),\n","              ('scada','append',{'ws': ws,'lh':lh}),\n","              ('download_excel',(\"raw/\", ws,lh)),\n","              ('duid','overwrite',{'ws': ws,'lh':lh}),\n","              ('calendar','ignore',{}),\n","              ('mstdatetime','ignore',{}),\n","              ('summary__backfill','overwrite',{}),\n","              ('deploy_model', (lh,schema,semantic_model,\"https://raw.githubusercontent.com/djouallah/fabric_demo/main/powerbi/Model.bim\")),\n","         ]\n","\n","intraday = [\n","              ('scrapingv2', ([\"http://nemweb.com.au/Reports/Current/DispatchIS_Reports/\",\"http://nemweb.com.au/Reports/Current/Dispatch_SCADA/\" ],\n","                            [\"Reports/Current/DispatchIS_Reports/\",\"Reports/Current/Dispatch_SCADA/\"],\n","                             288, ws,lh,Nbr_threads)),\n","              ('price_today','append',{'ws': ws,'lh':lh}),\n","              ('scada_today','append',{'ws': ws,'lh':lh}),\n","              ('duid','ignore',{'ws': ws,'lh':lh}),\n","              ('summary__incremental', 'append',{})            \n","          ]\n","\n","history_download = [('scrapingv2',([\"https://github.com/djouallah/fabric_demo/tree/main/data/archive/*\"],[\"Reports/Current/Daily_Reports/\"],nbr_days_download,ws,lh,Nbr_threads))]\n","\n","history_process = [('scada','append',{'ws': ws,'lh':lh}),('price','append',{'ws': ws,'lh':lh}),('summary__backfill_archive','append',{})]"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.395242Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:57.5522002Z","execution_finish_time":"2025-10-01T08:26:58.0018779Z","parent_msg_id":"9b280de6-43a4-4959-9bc4-b2578b26c900"}},"metadata":{}}],"execution_count":9,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"0cb55004-4897-450e-ae9d-42266a576085"},{"cell_type":"code","source":["%%time\n","#load the last 7 days and create  semantic model\n","con.run_pipeline(nightly)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.396728Z","session_start_time":null,"execution_start_time":"2025-10-01T08:26:58.003184Z","execution_finish_time":"2025-10-01T08:27:02.5373219Z","parent_msg_id":"0b179e14-56de-407f-90a1-0a09fe9a9a4f"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Running Task 1: create_lakehouse_if_not_exists ---\nRunning Python task: create_lakehouse_if_not_exists('dfcvb',)\n✅ Python task 'create_lakehouse_if_not_exists' completed.\n\n--- Running Task 2: scrapingv2 ---\nRunning Python task: scrapingv2(['https://nemweb.com.au/Reports/Current/Daily_Reports/'], ['Reports/Current/Daily_Reports/'], 7, 'sqlframe', 'dfcvb', 5)\nhttps://nemweb.com.au/Reports/Current/Daily_Reports/ - 0 files extracted (all 60 files already downloaded)\n✅ Python task 'scrapingv2' completed.\n❌ Task 2 failed. Stopping.\nCPU times: user 1.25 s, sys: 146 ms, total: 1.4 s\nWall time: 3.26 s\n"]},{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"False"},"metadata":{}}],"execution_count":10,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3348a4c5-068e-4300-a046-dd1f1da97b28"},{"cell_type":"code","source":["%%time\n","con.run_pipeline(intraday)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"finished","queued_time":"2025-10-01T08:26:14.398054Z","session_start_time":null,"execution_start_time":"2025-10-01T08:27:02.5385631Z","execution_finish_time":"2025-10-01T08:27:41.5371852Z","parent_msg_id":"9e640dd7-692e-4bc4-8f39-396cb0e7543a"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Running Task 1: scrapingv2 ---\nRunning Python task: scrapingv2(['http://nemweb.com.au/Reports/Current/DispatchIS_Reports/', 'http://nemweb.com.au/Reports/Current/Dispatch_SCADA/'], ['Reports/Current/DispatchIS_Reports/', 'Reports/Current/Dispatch_SCADA/'], 288, 'sqlframe', 'dfcvb', 5)\nFailed to download PUBLIC_DISPATCHIS_202510011650_0000000483000487.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHIS_202510011725_0000000483004040.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHIS_202510011635_0000000482998941.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHSCADA_202510010245_0000000482914092.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHIS_202510010440_0000000482925198.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHSCADA_202509301635_0000000482855428.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHIS_202509301700_0000000482858196.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHIS_202509301550_0000000482850674.zip: HTTP 403\nFlushed 70 files to disk and updated log Reports/Current/Dispatch_SCADA/download_log.csv\nFailed to download PUBLIC_DISPATCHSCADA_202509301125_0000000482821440.zip: HTTP 403\nFlushed 70 files to disk and updated log Reports/Current/DispatchIS_Reports/download_log.csv\nFailed to download PUBLIC_DISPATCHSCADA_202509300845_0000000482804422.zip: HTTP 403\nFlushed 70 files to disk and updated log Reports/Current/Dispatch_SCADA/download_log.csv\nFailed to download PUBLIC_DISPATCHIS_202509301030_0000000482815816.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHSCADA_202509300540_0000000482786722.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHIS_202509300935_0000000482809468.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHSCADA_202509300445_0000000482781741.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHIS_202509300905_0000000482806353.zip: HTTP 403\nFailed to download PUBLIC_DISPATCHSCADA_202509300045_0000000482758731.zip: HTTP 403\nFlushed 70 files to disk and updated log Reports/Current/Dispatch_SCADA/download_log.csv\nFlushed 70 files to disk and updated log Reports/Current/DispatchIS_Reports/download_log.csv\nFailed to download PUBLIC_DISPATCHSCADA_202509292325_0000000482751004.zip: HTTP 403\nFlushed 70 files to disk and updated log Reports/Current/Dispatch_SCADA/download_log.csv\nFlushed 70 files to disk and updated log Reports/Current/DispatchIS_Reports/download_log.csv\nFlushed 69 files to disk and updated log Reports/Current/DispatchIS_Reports/download_log.csv\nhttp://nemweb.com.au/Reports/Current/Dispatch_SCADA/ - 280 files extracted and uploaded\nhttp://nemweb.com.au/Reports/Current/DispatchIS_Reports/ - 279 files extracted and uploaded\n✅ Python task 'scrapingv2' completed.\n\n--- Running Task 2: price_today ---\n"]},{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447f9eeca1284e5f9f5f9448ec4ea9a8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ SQL task 'price_today' → table 'price_today' (append) completed.\n\n--- Running Task 3: scada_today ---\n"]},{"output_type":"display_data","data":{"text/plain":"FloatProgress(value=0.0, layout=Layout(width='auto'), style=ProgressStyle(bar_color='black'))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4943b912d3af4b2d8fbf3bd1d72f5cf7"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["✅ SQL task 'scada_today' → table 'scada_today' (append) completed.\n\n--- Running Task 4: duid ---\nTable duid exists. Skipping (mode='ignore').\n✅ SQL task 'duid' → table 'duid' (ignore) completed.\n\n--- Running Task 5: summary__incremental ---\n✅ SQL task 'summary__incremental' → table 'summary' (append) completed.\n\n✅ All tasks completed successfully.\nCPU times: user 7.06 s, sys: 505 ms, total: 7.56 s\nWall time: 37.6 s\n"]},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"True"},"metadata":{}}],"execution_count":11,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"3eed16b6-c7e1-4fb7-b85a-e7fb40c4ccf5"},{"cell_type":"code","source":["%%time\n","## you can turn it off when Historical data is fully loaded\n","con.run_pipeline(history_download)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":"e6987f5f-ebc0-437c-a25f-a82da9dd5711","normalized_state":"running","queued_time":"2025-10-01T08:26:14.3994142Z","session_start_time":null,"execution_start_time":"2025-10-01T08:27:41.5384435Z","execution_finish_time":null,"parent_msg_id":"ea80399f-565b-496b-a67a-fa3272d0e87b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n--- Running Task 1: scrapingv2 ---\nRunning Python task: scrapingv2(['https://github.com/djouallah/fabric_demo/tree/main/data/archive/*'], ['Reports/Current/Daily_Reports/'], 720, 'sqlframe', 'dfcvb', 5)\n"]}],"execution_count":12,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"a62bd1bb-42c1-46a7-8e02-7bb1b9125b98"},{"cell_type":"code","source":["con.run_pipeline(history_process)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.statement-meta+json":{"session_id":null,"normalized_state":"waiting","queued_time":"2025-10-01T08:26:14.4008406Z","session_start_time":null,"execution_start_time":null,"execution_finish_time":null,"parent_msg_id":"1821ce26-0501-4e58-b253-7011ddbe1982"}},"metadata":{}}],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"jupyter_python"}},"id":"db103456-1b37-4090-a737-753ef443768b"}],"metadata":{"kernel_info":{"jupyter_kernel_name":"python3.11","name":"jupyter"},"kernelspec":{"name":"jupyter","display_name":"Jupyter"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"jupyter_python","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"version_major":2,"version_minor":0,"state":{"4943b912d3af4b2d8fbf3bd1d72f5cf7":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":100,"style":"IPY_MODEL_9af1e5ad03024f1fbf243e848e5dba2e","layout":"IPY_MODEL_9277c82a16cc417b8c1fc6eec871f233"}},"447f9eeca1284e5f9f5f9448ec4ea9a8":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":44.73047930593088,"style":"IPY_MODEL_727dfe0f533d49779e5cd0e5c82551d8","layout":"IPY_MODEL_e9afe3cc7f1d498aaf22da3242d8d1fc"}},"941c1fce01ec48e8a401e77785ccf4de":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"auto"}},"79ef95dc2aa64ff88cdcc0c71ed6f979":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":56.94915254237289,"style":"IPY_MODEL_ac0618ac067340e7bbfe6d3034a49c1c","layout":"IPY_MODEL_0c088ff92ec5446bb2d49fb77365445b"}},"727dfe0f533d49779e5cd0e5c82551d8":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","bar_color":"black"}},"5dd43891023f41a5847efa5d7010beec":{"model_name":"FloatProgressModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"value":56.94915254237289,"style":"IPY_MODEL_4aa05d9c14654c95a4a8cff5a172c7c5","layout":"IPY_MODEL_941c1fce01ec48e8a401e77785ccf4de"}},"4aa05d9c14654c95a4a8cff5a172c7c5":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","bar_color":"black"}},"e9afe3cc7f1d498aaf22da3242d8d1fc":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"auto"}},"9af1e5ad03024f1fbf243e848e5dba2e":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","bar_color":"black"}},"0c088ff92ec5446bb2d49fb77365445b":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"auto"}},"9277c82a16cc417b8c1fc6eec871f233":{"model_name":"LayoutModel","model_module":"@jupyter-widgets/base","model_module_version":"2.0.0","state":{"width":"auto"}},"ac0618ac067340e7bbfe6d3034a49c1c":{"model_name":"ProgressStyleModel","model_module":"@jupyter-widgets/controls","model_module_version":"2.0.0","state":{"description_width":"","bar_color":"black"}}}}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{}}},"nbformat":4,"nbformat_minor":5}